# A Paper List of Yang Liu
- RSS 2023, **Diffusion Policy** Visuomotor Policy Learning via Action Diffusion, [Website](https://diffusion-policy.cs.columbia.edu/)
- arXiv 2024, **Catch It!**:Learning to Catch in Flight with Mobile Dexterous Hands, [Website](https://mobile-dex-catch.github.io/)
- CoRL 2024, **UMI on Legs**: Making Manipulation Policies Mobile with Manipulation-Centric Whole-body Controllers, [Website](https://umi-on-legs.github.io/)
- CoRL 2023, Seeing-Eye Quadruped Navigation with Force Responsive Locomotion Control, [Website](https://bu-air-lab.github.io/guide_dog/)
- arXiv 2024, **Survey**: Toward General-Purpose Robots via Foundation Models: A Survey and Meta-Analysis, [arXiv](https://arxiv.org/abs/2312.08782)
- RSS 2024, **GOAT**: GO to Any Thing, [Website](https://theophilegervet.github.io/projects/goat/)
- arXiv 2024, **GVL**:Vision Language Models are In-Context Value Learners, [Website](https://generative-value-learning.github.io/#online-demo)
- ECCV 2024, **COPL**:Visual Grounding for Object-Level Generalization in Reinforcement Learning, [arXiv](https://arxiv.org/abs/2408.01942)
- ICRA 2024, **Pedipulate**: Enabling Manipulation Skills using a Quadruped Robotâ€™s Leg, [Website](https://sites.google.com/leggedrobotics.com/pedipulate)
- ICRA 2023, Learning Whole-body Manipulation for Quadrupedal Robot, [arXiv](https://arxiv.org/abs/2308.16820)
- RSS 2023, **ALOHA**: Learning Fine-Grained Bimanual Manipulation with  Low-Cost Hardware, [Website](https://tonyzhaozh.github.io/aloha/)
- CoRL 2022, **Perceiver-Actor**: A Multi-Task Transformer for Robotic Manipulation, [Website](https://peract.github.io/)
- ICML 2021, **CLIP**: Learning Transferable Visual Models From Natural Language Supervision, [arXiv](https://arxiv.org/abs/2103.00020)
- ICRA 2024, **Talk Through It**: End User Directed Manipulation Learning, [Website](https://talk-through-it.github.io/)
- arXiv 2024, Walking with Terrain Reconstruction: Learning to Traverse Risky Sparse Footholds, [arXiv](https://arxiv.org/pdf/2409.15692)
- arXiv 2024, **Helpful DoggyBot**: Open-World Object Fetching using Legged Robots and Vision-Language Models, [Website](https://helpful-doggybot.github.io/)
- arXiv 2024, Open X-Embodiment: Robotic Learning Datasets and RT-X Models, [arXiv](https://arxiv.org/pdf/2310.08864)
- arXiv 2023, Anymal parkour: Learning agile navigation for quadrupedal robots, [arXiv](https://arxiv.org/abs/2306.14874)
- arXiv 2024, **Not Only Rewards But Also Constraints**:Applications on Legged Robot Locomotion, [arXiv](https://arxiv.org/pdf/2308.12517)
- arXiv 2023, **DreamWaQ**: Learning Robust Quadrupedal Locomotion With ImplicitTerrain Imagination via Deep Reinforcement Learning, [arXiv](https://arxiv.org/abs/2301.10602)
- arXiv 2024, Do As I Can, Not As I Say:Grounding Language in Robotic Affordances, [arXiv](https://arxiv.org/abs/2204.01691)
- RSS 2024, **RVT-2**: Learning Precise Manipulation from Few Examples, [Website](https://robotic-view-transformer-2.github.io/)
- Science Robotics 2024, Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning, [arxiv](https://arxiv.org/abs/2304.13653)
- RSS 2023, Robust Recovery Motion Control for Quadrupedal Robots via Learned Terrain Imagination, [Webiste](https://sites.google.com/view/dreamriser)
- CoRL 2020, **Transporter Networks**: Rearranging the Visual World for Robotic Manipulation, [Webiste](https://transporternets.github.io/)
- Nature Machine Intelligence 2024, Lifelike Agility and Play in Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models, [Website](https://tencent-roboticsx.github.io/lifelike-agility-and-play/)
- CoRL 2021, Minimizing Energy Consumption Leads to the Emergence of Gaits in Legged Robots, [Webiste](https://energy-locomotion.github.io/)
- CoRL 2023, Robot Parkour Learning, [Website](https://robot-parkour.github.io/)
- ICRA 2024, Extreme Parkour with Legged Robots, [Webisite](https://extreme-parkour.github.io/)
- ScienceDirect 2021, Development of quadruped walking robots: A review, [ScienceDirect](https://www.sciencedirect.com/science/article/pii/S2090447920302501)
- arXiv 2016, A Connection Between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models, [arXiv](https://arxiv.org/abs/1611.03852)
- ACM SIGGRAPH 2021, **AMP**: Adversarial Motion Priors for Stylized Physics-Based CharacterControl, [Website](https://xbpeng.github.io/projects/AMP/index.html)
- Science Robotics 2019, Learning agile and dynamic motor skills for legged robots, [Video](https://youtu.be/aTDkYFZFWug?si=uOz0P2ErlVum0TO0) / [arXiv](https://arxiv.org/abs/1901.08652)
- Science Robotics 2020, Learning Quadrupedal Locomotion over Challenging Terrain, [Website](https://leggedrobotics.github.io/rl-blindloco/)
- RSS 2021, **RMA**: Rapid Motor Adaptation for Legged Robots, [Website](https://ashish-kmr.github.io/rma-legged-robots/)
- CoRL 2022, Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning, [Website](https://leggedrobotics.github.io/legged_gym/) /  [arXiv](https://arxiv.org/abs/2109.11978)
- RA-L 2023, Learning Robust and Agile Legged Locomotion Using Adversarial Motion Priors, [bilibili](https://www.bilibili.com/video/BV1nM4y177rY/)



